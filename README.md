# Yapay ZekÃ¢ Destekli Kod Ãœretici Asistan

**FastAPI**, **Ollama** (yerel LLM) ve **Helm** kullanarak hazÄ±rlanmÄ±ÅŸ; kullanÄ±cÄ±dan alÄ±nan â€œpromptâ€â€™a gÃ¶re Python kodu ve kÄ±sa bir baÅŸlÄ±k Ã¼reten basit bir web uygulamasÄ±dÄ±r. Hem yerelde `uvicorn` ile Ã§alÄ±ÅŸtÄ±rabilir, hem Docker/Kubernetes/Helm ile Ã¶lÃ§ekleyebilirsin.

---

## âš™ï¸ Ã–zellikler

- **Prompt â†’ Kod**: KullanÄ±cÄ±nÄ±n girdiÄŸi doÄŸal dil promptâ€™unu alÄ±r  
- **BaÅŸlÄ±k**: Ãœretilen kodu Ã¶zetleyen kÄ±sa, anlamlÄ± bir baÅŸlÄ±k dÃ¶ner  
- **Web UI**: FastAPI + tek sayfalÄ±k HTML/CSS arayÃ¼z  
- **Yerel LLM**: Ollama + `llama3:latest` modeli  
- **Containerize**: Dockerfile hazÄ±r  
- **Kubernetes + Helm**: Helm chartâ€™Ä± ile tek komut deploy  

---

## ğŸ“¦ Gereksinimler

- Python 3.11+  
- [Ollama](https://ollama.com) (ve indirilmiÅŸ `llama3:latest` modeli)  
- Docker (isteÄŸe baÄŸlÄ±)  
- Minikube ve Helm (Kubernetes Ã¼zerine deploy iÃ§in)  

---

##  HÄ±zlÄ± BaÅŸlangÄ±Ã§

### 1. Projeyi klonlayÄ±n

```bash
git clone https://github.com/<KULLANICI_ADIN>/<REPO_ADIN>.git
cd <REPO_ADIN>
2. Python ortamÄ±nÄ± hazÄ±rlayÄ±n
bash
Kopyala
DÃ¼zenle
python -m venv venv
# Linux/macOS
source venv/bin/activate
# Windows
venv\Scripts\activate

pip install --upgrade pip
pip install -r requirements.txt
3. Ollama modelini Ã§ekin
bash
Kopyala
DÃ¼zenle
ollama pull llama3:latest
4. Ortam deÄŸiÅŸkenleri
bash
Kopyala
DÃ¼zenle
export OLLAMA_URL="http://localhost:11434"
export OLLAMA_MODEL="llama3:latest"
# Windows PowerShell:
#  $Env:OLLAMA_URL="http://localhost:11434"
#  $Env:OLLAMA_MODEL="llama3:latest"
5. UygulamayÄ± Ã§alÄ±ÅŸtÄ±rÄ±n
bash
Kopyala
DÃ¼zenle
uvicorn app.main:app --reload
TarayÄ±cÄ±da aÃ§: http://127.0.0.1:8000

 Docker ile Ã‡alÄ±ÅŸtÄ±rma
Ä°majÄ± oluÅŸturun:

bash
Kopyala
DÃ¼zenle
docker build -t <DOCKERHUB_KULLANICI_ADIN>/llm-code-generator:latest .
Ä°majÄ± pushâ€™layÄ±n:

bash
Kopyala
DÃ¼zenle
docker push <DOCKERHUB_KULLANICI_ADIN>/llm-code-generator:latest
Containerâ€™Ä± Ã§alÄ±ÅŸtÄ±rÄ±n:

bash
Kopyala
DÃ¼zenle
docker run -d -p 8000:8000 \
  -e OLLAMA_URL="http://host.docker.internal:11434" \
  -e OLLAMA_MODEL="llama3:latest" \
  <DOCKERHUB_KULLANICI_ADIN>/llm-code-generator:latest
UIâ€™ye gidin: http://localhost:8000

 Kubernetes + Helm ile Deploy
Minikubeâ€™u baÅŸlatÄ±n:

bash
Kopyala
DÃ¼zenle
minikube start
Helm chart dizinine gidin:

bash
Kopyala
DÃ¼zenle
cd helm/llm-code-generator
Chartâ€™Ä± yÃ¼kleyin:

bash
Kopyala
DÃ¼zenle
helm install my-llm-code-generator .
Servis URLâ€™sini alÄ±n:

bash
Kopyala
DÃ¼zenle
minikube service my-llm-code-generator --url
TarayÄ±cÄ±da aÃ§Ä±n ve prompt girip â€œÃœretâ€e tÄ±klayÄ±n.